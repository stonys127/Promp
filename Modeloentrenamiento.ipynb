{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZOnJuZgaQLM",
        "outputId": "ff8ad2de-51bd-4375-c4c7-cf690deaa007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OfSKQ4XiaPa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de entrenamiento"
      ],
      "metadata": {
        "id": "E33IM0dfBEr3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBJixtJot3jb",
        "outputId": "5217615a-d9c2-4705-b195-a27a0d0dbbf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "3/3 [==============================] - 2s 264ms/step - loss: 288.6753 - accuracy: 0.4783\n",
            "Epoch 2/15\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 150.6629 - accuracy: 0.4348\n",
            "Epoch 3/15\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 167.2728 - accuracy: 0.4928\n",
            "Epoch 4/15\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 121.1424 - accuracy: 0.5652\n",
            "Epoch 5/15\n",
            "3/3 [==============================] - 1s 146ms/step - loss: 150.2938 - accuracy: 0.5217\n",
            "Epoch 6/15\n",
            "3/3 [==============================] - 1s 137ms/step - loss: 144.2567 - accuracy: 0.5362\n",
            "Epoch 7/15\n",
            "3/3 [==============================] - 1s 143ms/step - loss: 73.5683 - accuracy: 0.4928\n",
            "Epoch 8/15\n",
            "3/3 [==============================] - 1s 135ms/step - loss: 89.4526 - accuracy: 0.5652\n",
            "Epoch 9/15\n",
            "3/3 [==============================] - 1s 140ms/step - loss: 103.6186 - accuracy: 0.5652\n",
            "Epoch 10/15\n",
            "3/3 [==============================] - 0s 131ms/step - loss: 58.2449 - accuracy: 0.6522\n",
            "Epoch 11/15\n",
            "3/3 [==============================] - 1s 135ms/step - loss: 67.4686 - accuracy: 0.6087\n",
            "Epoch 12/15\n",
            "3/3 [==============================] - 1s 137ms/step - loss: 25.3844 - accuracy: 0.7101\n",
            "Epoch 13/15\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 63.2460 - accuracy: 0.6377\n",
            "Epoch 14/15\n",
            "3/3 [==============================] - 0s 138ms/step - loss: 9.7097 - accuracy: 0.8696\n",
            "Epoch 15/15\n",
            "3/3 [==============================] - 1s 137ms/step - loss: 23.2453 - accuracy: 0.7391\n",
            "Evaluación en datos de entrenamiento: [3.817342519760132, 0.9420289993286133]\n",
            "Evaluación en datos de prueba: [10.179636001586914, 0.8571428656578064]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from librosa.util import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definir listas para almacenar espectrogramas y etiquetas\n",
        "spectrogram_list = []\n",
        "labels_list = []\n",
        "\n",
        "# Carpetas de palabras (entrenamiento)\n",
        "palabra1_folder = '/content/drive/MyDrive/turnoff'\n",
        "palabra2_folder = '/content/drive/MyDrive/ turn on'\n",
        "\n",
        "# Definir etiquetas para las palabras\n",
        "labels_mapping = {\n",
        "    'palabra1': 0,\n",
        "    'palabra2': 1,\n",
        "}\n",
        "\n",
        "# Función para cargar espectrogramas y etiquetas\n",
        "def load_spectrograms_and_labels(folder, label):\n",
        "    spectrogram_list = []\n",
        "    labels_list = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith('.wav'):\n",
        "            filepath = os.path.join(folder, filename)\n",
        "            audio, _ = librosa.load(filepath, sr=None)\n",
        "            spectrogram = librosa.feature.melspectrogram(y=audio, sr=44100)\n",
        "            spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "            if spectrogram.shape[1] < 128:\n",
        "                pad_width = 128 - spectrogram.shape[1]\n",
        "                spectrogram = np.pad(spectrogram, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "            else:\n",
        "                spectrogram = spectrogram[:, :128]\n",
        "            spectrogram_list.append(spectrogram)\n",
        "            labels_list.append(label)\n",
        "    return spectrogram_list, labels_list\n",
        "\n",
        "# Cargar espectrogramas y etiquetas para cada palabra\n",
        "spectrogram_list_p1, labels_list_p1 = load_spectrograms_and_labels(palabra1_folder, labels_mapping['palabra1'])\n",
        "spectrogram_list_p2, labels_list_p2 = load_spectrograms_and_labels(palabra2_folder, labels_mapping['palabra2'])\n",
        "\n",
        "# Combinar las listas de espectrogramas y etiquetas\n",
        "spectrogram_list = spectrogram_list_p1 + spectrogram_list_p2\n",
        "labels_list = labels_list_p1 + labels_list_p2\n",
        "\n",
        "# Convierte las listas de espectrogramas y etiquetas en matrices de datos\n",
        "X = np.array(spectrogram_list)\n",
        "y = np.array(labels_list)\n",
        "\n",
        "# División en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Añadir una dimensión adicional para el canal\n",
        "X_train = X_train[:, :, :, np.newaxis]\n",
        "X_test = X_test[:, :, :, np.newaxis]\n",
        "\n",
        "# Define el modelo de aprendizaje automático\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(128, 128, 1)),\n",
        "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(2, activation='softmax')  # Cambiado a 2 clases\n",
        "])\n",
        "\n",
        "# Compila el modelo\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrena el modelo\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "# Evalúa el modelo\n",
        "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Evaluación en datos de entrenamiento:', train_score)\n",
        "\n",
        "# Carpeta de palabras de prueba\n",
        "palabra1_test_folder = '/content/drive/MyDrive/turnofftest'\n",
        "palabra2_test_folder = '/content/drive/MyDrive/turnontest'\n",
        "\n",
        "# Definir listas para almacenar espectrogramas y etiquetas de prueba\n",
        "spectrogram_test_list = []\n",
        "labels_test_list = []\n",
        "\n",
        "# Cargar espectrogramas y etiquetas para cada palabra de prueba\n",
        "spectrogram_test_list_p1, labels_test_list_p1 = load_spectrograms_and_labels(palabra1_test_folder, labels_mapping['palabra1'])\n",
        "spectrogram_test_list_p2, labels_test_list_p2 = load_spectrograms_and_labels(palabra2_test_folder, labels_mapping['palabra2'])\n",
        "\n",
        "# Combinar las listas de espectrogramas y etiquetas de prueba\n",
        "spectrogram_test_list = spectrogram_test_list_p1 + spectrogram_test_list_p2\n",
        "labels_test_list = labels_test_list_p1 + labels_test_list_p2\n",
        "\n",
        "# Convierte las listas de prueba en matrices de datos\n",
        "X_test = np.array(spectrogram_test_list)\n",
        "y_test = np.array(labels_test_list)\n",
        "\n",
        "# Añadir una dimensión adicional para el canal\n",
        "X_test = X_test[:, :, :, np.newaxis]\n",
        "\n",
        "# Evaluar el modelo en los datos de prueba\n",
        "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Evaluación en datos de prueba:', test_score)\n",
        "\n",
        "# Guarda el modelo\n",
        "model.save('/content/drive/MyDrive/tu_modelo.h6')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga de el modelo estadistico ''modelo.h''"
      ],
      "metadata": {
        "id": "4AxsAqB2BHfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/tu_modelo.h6')"
      ],
      "metadata": {
        "id": "-vovbQEibVA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model = keras.models.load_model('/content/drive/MyDrive/tu_modelo.h6')\n",
        "\n",
        "# Hacer predicciones con el modelo\n",
        "# Puedes usar este modelo para hacer predicciones en nuevos datos de audio de la misma manera que lo hiciste en el código original.\n",
        "\n",
        "# Ejemplo de cómo hacer una predicción en un espectrograma (X_new es tu nuevo espectrograma)\n",
        "# prediction = model.predict(X_new)\n",
        "\n",
        "# Puedes ajustar 'X_new' según tus necesidades y datos de entrada.\n",
        "\n",
        "# Si deseas visualizar la arquitectura del modelo, puedes usar la función 'summary':\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMrdVNHpbWED",
        "outputId": "5473bd1a-d3a1-4796-cc61-194925704252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 127008)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 254018    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 254338 (993.51 KB)\n",
            "Trainable params: 254338 (993.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prueba de modelo.h"
      ],
      "metadata": {
        "id": "Yf0ztQILBQX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from tensorflow import keras\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el modelo\n",
        "model = keras.models.load_model('/content/drive/MyDrive/tu_modelo.h6')  # Asegúrate de proporcionar la ruta correcta si el modelo no está en el mismo directorio.\n",
        "\n",
        "# Ruta del archivo de audio que deseas clasificar\n",
        "audio_file_path = '/content/drive/MyDrive/turnoff/descarga (11).wav'  # Cambia la ruta a tu archivo de audio\n",
        "\n",
        "# Función para cargar y preprocesar un archivo de audio\n",
        "def load_and_process_audio(file_path):\n",
        "    audio, _ = librosa.load(file_path, sr=None)\n",
        "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=44100)\n",
        "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "    if spectrogram.shape[1] < 128:\n",
        "        pad_width = 128 - spectrogram.shape[1]\n",
        "        spectrogram = np.pad(spectrogram, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        spectrogram = spectrogram[:, :128]\n",
        "    spectrogram = spectrogram[:, :, np.newaxis]\n",
        "    return spectrogram\n",
        "\n",
        "# Cargar y preprocesar el archivo de audio\n",
        "spectrogram = load_and_process_audio(audio_file_path)\n",
        "\n",
        "# Realizar la predicción\n",
        "prediction = model.predict(np.array([spectrogram]))  # El modelo espera un batch de datos, por eso usamos np.array([spectrogram]).\n",
        "\n",
        "# La salida 'prediction' contendrá las probabilidades para cada clase.\n",
        "# Imprime las probabilidades para interpretación manual.\n",
        "print(\"Probabilidades de cada clase:\", prediction)\n",
        "\n",
        "# Establecer un umbral para clasificar\n",
        "threshold = 0.5\n",
        "\n",
        "# Clasificar la predicción\n",
        "if prediction[0][0] > threshold:\n",
        "    print(\"Turn off kitchen light\")\n",
        "else:\n",
        "    print(\"Turn on kitchen light\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukEKgkD1ctfe",
        "outputId": "ea45a9f1-11cb-4cff-fca8-4b5a6aa8eef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 351ms/step\n",
            "Probabilidades de cada clase: [[1. 0.]]\n",
            "Turn off kitchen light\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "descarga del modelo.h\n"
      ],
      "metadata": {
        "id": "WifDWntGBT0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"const unsigned char tu_modelo[] = {\" > /content/model.h\n",
        "!cat /content/drive/MyDrive/tu_modelo.h6 | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"/content/model.h\")\n",
        "print(f\"El archivo de encabezado, model.h, tiene un tamaño de {model_h_size:,} bytes.\")\n",
        "print(\"\\nAbra el panel lateral (actualice si es necesario). Haga doble clic en model.h para descargar el archivo.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEILgF-sgBgM",
        "outputId": "661e5018-a60a-491f-f008-fce260e00446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /content/drive/MyDrive/tu_modelo.h6: Is a directory\n",
            "El archivo de encabezado, model.h, tiene un tamaño de 39 bytes.\n",
            "\n",
            "Abra el panel lateral (actualice si es necesario). Haga doble clic en model.h para descargar el archivo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ],
      "metadata": {
        "id": "dgH6ubWsgK_o"
      }
    }
  ]
}